{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b767438f",
   "metadata": {},
   "source": [
    "## Imports libraries and display settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d252bddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import cm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "import time\n",
    "from scipy.stats import pearsonr\n",
    "import math\n",
    "import matplotlib.backends.backend_pdf\n",
    "from scipy.stats import zscore\n",
    "import pickle\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892d4915",
   "metadata": {},
   "source": [
    "## Small math functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553c1619",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split time-series data \"a\" into \"n\" segments (i.e. downsampling to \"n\" samples)\n",
    "def split(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return (a[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(n))\n",
    "\n",
    "## Calculate parametric Pearson correlation p-value ##\n",
    "def calculate_pvalues(df):\n",
    "    dfcols = pd.DataFrame(columns=df.columns)\n",
    "    pvalues = dfcols.transpose().join(dfcols, how='outer')\n",
    "    for r in df.columns:\n",
    "        for c in df.columns:\n",
    "            tmp = df[df[r].notnull() & df[c].notnull()]\n",
    "            pvalues[r][c] = round(pearsonr(tmp[r], tmp[c])[1], 4)\n",
    "    return pvalues\n",
    "\n",
    "## Calculate absolute distance between 2 values ##\n",
    "def distance(x, y):\n",
    "    if x >= y:\n",
    "        result = x - y\n",
    "    else:\n",
    "        result = y - x\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb650cd",
   "metadata": {},
   "source": [
    "## Define plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1447ea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_extract_correlated_ROIs(r_thresh, event_thresh, time_thresh):\n",
    "    \n",
    "    \"\"\"Plots correlated ROI pairs from \"cohort_correlation\" dict (individual mouse .npy files saved elsewhere in a previous script), and saves plots as a pdf. \n",
    "    There is also the option of re-defining new correlation criteria, and saves these correlation metrics as a .npy file.\n",
    "    \n",
    "    Parameters\n",
    "        r_thresh: minimum Pearson r correlation coeffcient required for a pair of ROIs to be considered correlated\n",
    "        event_thresh: minimum proportion of shared calcium events required for a pair of ROIs to be considered correlated\n",
    "        time_thresh: maximum number of frames between calciume events to be considered a \"shared events\"\n",
    "        \n",
    "    Returns:\n",
    "        Plots correlated ROIs session traces if the pdf for the given correlation criteria doesn't already exist.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Pdf file naming/directory setup ##\n",
    "    fname = 'correlated_ROIs_'+str(r_thresh)+'rthresh_'+str(event_thresh)+'eventthresh' #pdf filename based on correlation criteria\n",
    "    \n",
    "    if fname+'.pdf' in os.listdir(cwd):\n",
    "        print(fname+'.pdf already exists') #no function performed if pdf already exists for the current criteria\n",
    "    else:\n",
    "        pdf = matplotlib.backends.backend_pdf.PdfPages(fname+'.pdf') #open up a new pdf with the new filename\n",
    "        \n",
    "        ## Loop through nested structure of input dictionaries (mouse --> session --> ROI) ##\n",
    "        correlated_ROIs = {} #final dictionary to add correlation metrics to (with new correlation criteria considered)\n",
    "        for mouse, mouse_dict in cohort_correlations.items():\n",
    "            correlated_ROIs[mouse] = {}\n",
    "            if 'cross-pairs' in mouse_dict.keys(): #look specifically at correlated pairs of ROIs across channels (as determined by previous script)\n",
    "                for session, session_dict in mouse_dict['cross-pairs'].items():\n",
    "                    session_split = session.split('_') #session name should be in the format \"protocol_date_FOV\"\n",
    "                    FPS = cohort_params[mouse][session_split[0]][session_split[1]][session_split[2]]['FPS'] #get image acquisition framerate from \"cohort_params\" dict\n",
    "                    \n",
    "                    ## For each ROI, extract the deltaF/events ##\n",
    "                    for ROI, ROI_dict in session_dict.items():\n",
    "                        mouse_df = cohort_deltaF[mouse] #mouse deltaF (i.e. all ROIs/sessions) of the current ROI\n",
    "                        ROI_df = mouse_df[mouse_df.index.get_level_values('Unique_ROI') == ROI] #deltaF of the current ROI\n",
    "                        trials = ROI_df.index.get_level_values('Trial') #trial numbers of the current ROI\n",
    "                        ROI_df = (ROI_df - ROI_df.min().min()) / (ROI_df.max().max() - ROI_df.min().min()) #normalized deltaF of each trial for the current ROI\n",
    "                        ROI_flat = ROI_df.to_numpy().flatten() #concatenate all trials of deltaF and flatten to 1-d array\n",
    "                        mouse_events = cohort_events[mouse] #mouse events (i.e. all ROIs/sessions) of the current ROI\n",
    "                        ROI_events = mouse_events[mouse_events['Unique_ROI'] == ROI] #events of the current ROI\n",
    "                        \n",
    "                        ## Find peak times of all events for current ROI ##\n",
    "                        ROI_peak_times = []\n",
    "                        for index, rows in ROI_events.iterrows():\n",
    "                            trial_idx = np.where(np.asarray(trials) == rows.Trial)[0][0] #find deltaF index of the trial corresponding to the current event in the loop\n",
    "                            peak_time = (trial_idx*ROI_df.shape[1]) + (rows['peak_time']*FPS) #(trial number*nframes per trial) + (peak time for current trial*framerate) to determine peak frame number for session trace\n",
    "                            ROI_peak_times.append(peak_time) if peak_time < ROI_flat.shape[0] else None \n",
    "                        ROI_peaks = [ROI_flat[math.ceil(x)] for x in ROI_peak_times] #use peak times to get peak deltaF values from \"ROI_flat\"\n",
    "\n",
    "                        ROI_color = 'green' if 'Green' in ROI else 'red'\n",
    "                        ROI_label = ('_').join(ROI.split('_')[-2:])\n",
    "                        \n",
    "                        ## Extract deltaF/events and find peak times of all events for other ROIs in the same FOV (i.e. partner ROIs) ##\n",
    "                        for partner, r in ROI_dict.items(): #ROI_dict contains every ROI (i.e. partner) that was correlated with the current ROI (from previous script)\n",
    "                            if r > r_thresh: #Pearson r threshold\n",
    "                                partner_df = mouse_df[mouse_df.index.get_level_values('Unique_ROI') == partner]\n",
    "                                partner_df = (partner_df - partner_df.min().min()) / (partner_df.max().max() - partner_df.min().min())\n",
    "                                partner_flat = partner_df.to_numpy().flatten()\n",
    "                                partner_flat = partner_flat-0.75 #subtract 0.75 from normalized deltaF of partner ROI for plotting purposes (i.e. to view stacked on top of each other)\n",
    "\n",
    "                                partner_events = mouse_events[mouse_events['Unique_ROI'] == partner]\n",
    "                                partner_peak_times = []\n",
    "                                for index, rows in partner_events.iterrows():\n",
    "                                    trial_idx = np.where(np.asarray(trials) == rows.Trial)[0][0]\n",
    "                                    peak_time = (trial_idx*partner_df.shape[1]) + (rows['peak_time']*FPS)\n",
    "                                    partner_peak_times.append(peak_time) if peak_time < partner_flat.shape[0] else None\n",
    "                                partner_peaks = [partner_flat[math.ceil(x)] for x in partner_peak_times]\n",
    "\n",
    "                                partner_color = 'green' if 'Green' in partner else 'red'\n",
    "                                partner_label = ('_').join(partner.split('_')[-2:])\n",
    "                                \n",
    "                                ## Find shared events between current ROI and current partner ROI ##\n",
    "                                matched_event_times = []\n",
    "                                matched_event_peaks = []\n",
    "                                for ROI_time, ROI_peak in zip(ROI_peak_times, ROI_peaks):\n",
    "                                    for partner_time in partner_peak_times:\n",
    "                                        if distance(ROI_time, partner_time) <= time_thresh:\n",
    "                                            matched_event_times.append(ROI_time)\n",
    "                                            matched_event_peaks.append(ROI_peak+0.1) #want to plot an asterisk 0.1 units above the actual peak of the trace\n",
    "                                \n",
    "                                ## Calculate shared event ratio, and plot ROI-pair if it is above the threshold ##\n",
    "                                event_ratio = len(matched_event_times) / len(ROI_peak_times)\n",
    "                                if event_ratio > event_thresh:\n",
    "                                    if ROI not in correlated_ROIs[mouse].keys():\n",
    "                                        correlated_ROIs[mouse][ROI] = {}\n",
    "                                        correlated_ROIs[mouse][ROI][partner] = {'r':r, 'event_ratio':event_ratio}\n",
    "                                    else:\n",
    "                                        correlated_ROIs[mouse][ROI][partner] = {'r':r, 'event_ratio':event_ratio}\n",
    "                                   \n",
    "                                    fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(20,4))\n",
    "                                    fig.suptitle(mouse+'_'+session+' \\n '+ROI_label, fontsize=25, y=0.98)\n",
    "                                    ax.plot(partner_flat, color=partner_color, alpha=0.3)\n",
    "                                    ax.plot(ROI_flat, color=ROI_color,alpha=0.3)\n",
    "\n",
    "                                    ax.scatter(y=ROI_peaks, x=ROI_peak_times, color=ROI_color, marker='*', s=15)\n",
    "                                    ax.scatter(y=partner_peaks, x=partner_peak_times, color=partner_color, marker='*', s=15)\n",
    "                                    ax.scatter(y=matched_event_peaks, x=matched_event_times, color='orange', marker='*', s=25)\n",
    "\n",
    "                                    ax.set_title(partner_label, fontsize=15)  \n",
    "                                    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "                                    pdf.savefig(fig)\n",
    "        np.save(fname+'.npy', correlated_ROIs)\n",
    "        pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae74cf2",
   "metadata": {},
   "source": [
    "## Data uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d7522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd() #current working directory\n",
    "somas = {'RGECO_GCamP_Batch2_five':[],'RGECO_GCamP_Batch2_three':['FOV4']} #somatic recording sessions (to remove from \"Red\" channel data)\n",
    "nmice = 8\n",
    "random_colors = cm.rainbow(np.linspace(0,1,nmice)) #get array of random colors (nmice = number of different colors)\n",
    "ID_colors = {}\n",
    "cohort_epochs = {}\n",
    "\n",
    "## Loop through every sub-directory in the current working directory to find different datatypes (defined by the iterator dtype) ##\n",
    "for dtype in ['events','deltaF','pupil']:\n",
    "    cohort_dtype = {}\n",
    "    for root, dirs, files in os.walk(cwd):\n",
    "        for f in files:\n",
    "            if (dtype+'_epochs' in f) & ('Old version' not in root):\n",
    "                ID = root.split('\\\\')[-1]\n",
    "                ID_dtype = np.load(root+'\\\\'+f, allow_pickle=True).item()\n",
    "\n",
    "                for epoch, epoch_df in ID_dtype.items():\n",
    "                    if dtype not in cohort_epochs.keys():\n",
    "                        cohort_epochs[dtype] = {}\n",
    "                        \n",
    "                        if epoch not in cohort_epochs[dtype].keys():\n",
    "                            cohort_epochs[dtype][epoch] = {}\n",
    "                            cohort_epochs[dtype][epoch][ID] = epoch_df\n",
    "                        else:\n",
    "                            cohort_epochs[dtype][epoch][ID] = epoch_df\n",
    "                    else:\n",
    "                        if epoch not in cohort_epochs[dtype].keys():\n",
    "                            cohort_epochs[dtype][epoch] = {}\n",
    "                            cohort_epochs[dtype][epoch][ID] = epoch_df\n",
    "                        else:\n",
    "                            cohort_epochs[dtype][epoch][ID] = epoch_df\n",
    "                            \n",
    "for i, (mouse) in enumerate(cohort_epochs['deltaF']['all'].keys()):\n",
    "    ID_colors[mouse] = random_colors[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149615ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_deltaF = {}\n",
    "cohort_correlations = {}\n",
    "cohort_pupil = {}\n",
    "cohort_events = {}\n",
    "cohort_params = {}\n",
    "for root, dirs, files in os.walk(cwd):\n",
    "    for f in files:\n",
    "        if ('processed_calcium.npy' in f) & ('Old version' not in root):\n",
    "            ID = root.split('\\\\')[-1]\n",
    "            ID_calcium = np.load(root+'\\\\'+f, allow_pickle=True).item()\n",
    "            ID_deltaF = ID_calcium['deltaF']\n",
    "            ID_correlations = ID_calcium['correlations']\n",
    "            ID_events = ID_calcium['events']\n",
    "            cohort_deltaF[ID] = ID_deltaF\n",
    "            cohort_correlations[ID] = ID_correlations\n",
    "            cohort_events[ID] = ID_events\n",
    "        if ('processed_pupil.csv' in f) & ('Old version' not in root):\n",
    "            ID = root.split('\\\\')[-1]\n",
    "            ID_pupil = pd.read_csv(root+'\\\\'+f, index_col=list(range(17)))\n",
    "            cohort_pupil[ID] = ID_pupil\n",
    "        if ('params.npy' in f) & ('Old version' not in root):\n",
    "            ID = root.split('\\\\')[-1]\n",
    "            ID_params = np.load(root+'\\\\'+f, allow_pickle=True).item()\n",
    "            cohort_params[ID] = ID_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2613b957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redefine_outcomes(deltaF):\n",
    "    final_outcomes = []\n",
    "    for index, rows in deltaF.iterrows():\n",
    "        rew = index[12]\n",
    "        outcome = index[16]\n",
    "        ttype = index[15]\n",
    "\n",
    "        if ttype == float(1):\n",
    "            if rew == float(1):\n",
    "                final = 'Tactile rewarded '+outcome\n",
    "            else:\n",
    "                final = 'Tactile unrewarded '+outcome\n",
    "        elif ttype == float(2):\n",
    "            if rew == float(1):\n",
    "                final = 'Auditory rewarded '+outcome\n",
    "            else:\n",
    "                final = 'Auditory unrewarded '+outcome        \n",
    "        else:\n",
    "            if rew == float(1):\n",
    "                final = 'Catch rewarded '+outcome\n",
    "            else:\n",
    "                final = 'Catch unrewarded '+outcome           \n",
    "        final_outcomes.append(final)\n",
    "    \n",
    "    deltaF.index = pd.MultiIndex.from_tuples([tuple(list(x) + [final_outcomes[i]]) for i, (x) in enumerate(deltaF.index)], names=deltaF.index.names+['Final Outcome'])           \n",
    "    \n",
    "    return deltaF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dff1153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_posteriors(group_df, size, protocol, dtype):\n",
    "    if dtype == 'pupil':\n",
    "        outcome_label = 'Outcome'\n",
    "    elif dtype == 'calcium':\n",
    "        outcome_label = 'Final Outcome'\n",
    "    else:\n",
    "        print('invalid dtype')\n",
    "        \n",
    "    posteriors = {}\n",
    "    for block in range(1000):        \n",
    "        if block+size > group_df.shape[0]:\n",
    "            break\n",
    "        else:\n",
    "            block_df = group_df[block:block+size]\n",
    "    \n",
    "            posteriors[block] = {}\n",
    "            posteriors[block]['reward prob'] = {}\n",
    "            posteriors[block]['stimulus ratios'] = {}\n",
    "            posteriors[block]['response rate'] = {}\n",
    "            posteriors[block]['rare prob'] = {}\n",
    "\n",
    "            \n",
    "            if 'det' not in protocol:\n",
    "                Go_ID = block_df[(block_df[outcome_label].str.contains('hit')) | (block_df[outcome_label].str.contains('miss'))].Stimulus.iloc[0]\n",
    "                NoGo_ID = float(1) if Go_ID == float(2) else float(2)\n",
    "                Go = block_df[block_df.Stimulus == Go_ID]\n",
    "                NoGo = block_df[block_df.Stimulus == NoGo_ID]\n",
    "            else:\n",
    "                Go = block_df[block_df.Stimulus != float(3)]\n",
    "                NoGo = block_df[block_df.Stimulus == float(3)]\n",
    "                \n",
    "            rew_probs = {}\n",
    "            response_probs = {}\n",
    "            for m, modality in zip(['G','N'],[Go, NoGo]):\n",
    "                nFA = modality[modality[outcome_label].str.contains('FA')].shape[0]\n",
    "                nHIT = modality[modality[outcome_label].str.contains('hit')].shape[0]\n",
    "                ntype = modality.shape[0]\n",
    "                nrew = modality[modality.Water == float(1)].shape[0]\n",
    "                rew_prob = nrew/(nFA+nHIT) if nFA+nHIT > 2 else np.nan\n",
    "                rew_probs[m] = rew_prob\n",
    "                response_probs[m]  = (nFA+nHIT)/ntype\n",
    "            rare = Go[(Go.Water == float(0)) & (Go[outcome_label].str.contains('hit'))].shape[0] + NoGo[(NoGo.Water == float(1)) & (NoGo[outcome_label].str.contains('FA'))].shape[0]\n",
    "            frequent = Go[(Go.Water == float(1)) & (Go[outcome_label].str.contains('hit'))].shape[0] + NoGo[(NoGo.Water == float(0)) & (NoGo[outcome_label].str.contains('FA'))].shape[0]\n",
    "            if (rare > 2) & (frequent > 2):\n",
    "                posteriors[block]['rare prob'] = rare/frequent\n",
    "            else:\n",
    "                posteriors[block]['rare prob'] = np.nan\n",
    "            posteriors[block]['reward prob'] = rew_probs\n",
    "            posteriors[block]['response rate'] = response_probs\n",
    "            \n",
    "            ntrials = block_df.shape[0]\n",
    "            posteriors[block]['stimulus ratios'] = {'G':Go.shape[0]/ntrials,\n",
    "                                                    'N':NoGo.shape[0]/ntrials}\n",
    "    \n",
    "    return posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd814a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pupil = pd.concat(cohort_pupil)\n",
    "pupil_behavior = []\n",
    "for mouse in all_pupil.index.get_level_values(0).unique():\n",
    "    mouse_df = all_pupil[all_pupil.index.get_level_values(0) == mouse]\n",
    "    for session in mouse_df.index.get_level_values('Unique session').unique():\n",
    "        session_df = mouse_df[mouse_df.index.get_level_values('Unique session') == session]\n",
    "        protocol = session_df.index.get_level_values('Protocol')[0]\n",
    "        first_channel = session_df.index.get_level_values('Channel').unique()[0]\n",
    "        first_channel_df = session_df[session_df.index.get_level_values('Channel') == first_channel]\n",
    "        first_channel_df = first_channel_df.reset_index().iloc[:,:18]\n",
    "        first_channel_df = first_channel_df.rename({'level_0':'ID'}, axis=1)\n",
    "        first_channel_df['Anticipatory licks'] = [x+1 for x in list(first_channel_df['Anticipatory licks'])]\n",
    "        first_channel_df['Response latency'] = [(float(x)/1000)-3 for x in list(first_channel_df['Response latency'].replace({'-':np.nan}))]\n",
    "        if (len(first_channel_df['Trial type'].unique()) > 1) & (first_channel_df.shape[0] > 30):\n",
    "            posteriors_df = pd.DataFrame(calculate_posteriors(first_channel_df, first_channel_df.shape[0], protocol, 'pupil')[0])\n",
    "            prop_rare = posteriors_df['rare prob']['G']\n",
    "            hit_rate = posteriors_df['response rate']['G']\n",
    "            FA_rate = posteriors_df['response rate']['N']\n",
    "            correct = first_channel_df[(first_channel_df.Outcome  == 'hit') | (first_channel_df.Outcome  == 'CR')].shape[0]\n",
    "            CP_rate = correct/first_channel_df.shape[0]\n",
    "            FA_latency = (first_channel_df[first_channel_df.Outcome == 'FA']['Response latency']).mean()\n",
    "            hit_latency = (first_channel_df[first_channel_df.Outcome == 'hit']['Response latency']).mean()\n",
    "            FA_licks = (first_channel_df[first_channel_df.Outcome == 'FA']['Anticipatory licks']).mean()\n",
    "            hit_licks = (first_channel_df[first_channel_df.Outcome == 'hit']['Anticipatory licks']).mean()\n",
    "            norm_licks = FA_licks/hit_licks\n",
    "            FA_licks_rew = (first_channel_df[(first_channel_df.Outcome == 'FA') & (first_channel_df.Water == float(1))][' Reward licks']).mean()\n",
    "            hit_licks_rew = (first_channel_df[(first_channel_df.Outcome == 'hit') & (first_channel_df.Water == float(1))][' Reward licks']).mean()\n",
    "            final_df = pd.DataFrame([CP_rate, hit_rate, FA_rate, prop_rare, norm_licks, hit_licks, FA_licks, hit_licks_rew, FA_licks_rew, hit_latency, FA_latency, protocol], \n",
    "                                    index=['CP rate','Hit rate','FA rate','Rare outcome proportion','Hit/FA licks', 'Hit ant', 'FA ant', 'Hit rew','FA rew', 'Hit latency','FA latency', 'Protocol'], \n",
    "                                    columns=[mouse+'_'+session]).T\n",
    "            final_df = final_df.reset_index().set_index(['index','Protocol'])\n",
    "            pupil_behavior.append(final_df)\n",
    "pupil_behavior = pd.concat(pupil_behavior)\n",
    "pupil_behavior.index = pupil_behavior.index.set_names('FOV',level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc45b7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_deltaF = pd.concat(cohort_deltaF)\n",
    "deltaF = redefine_outcomes(all_deltaF)\n",
    "expectation = []\n",
    "for index, rows in deltaF.iterrows():\n",
    "    t = index[20]\n",
    "    if t in ['Tactile rewarded hit', 'Auditory rewarded hit', 'Tactile unrewarded FA', 'Auditory unrewarded FA']:\n",
    "        expectation.append('expected')\n",
    "    elif t in ['Tactile rewarded FA', 'Auditory rewarded FA', 'Tactile unrewarded hit', 'Auditory unrewarded hit']:\n",
    "        expectation.append('unexpected')\n",
    "    else:\n",
    "        expectation.append('no expectation')\n",
    "deltaF['expectation'] = expectation\n",
    "values = [x+(y,) for x,y in zip(deltaF.index.values, deltaF['expectation'])]\n",
    "names = list(deltaF.index.names)\n",
    "names.append('expectation')\n",
    "deltaF.index = pd.MultiIndex.from_tuples(values, names=names)\n",
    "deltaF = deltaF.iloc[:,:-1]\n",
    "deltaF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dcff8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extinction_df = deltaF[deltaF.index.get_level_values('Protocol').str.contains('det')]\n",
    "for channel in ['Red','Green']:\n",
    "    channel_df = extinction_df[extinction_df.index.get_level_values('Channel') == channel]\n",
    "    ROI_groups = channel_df.groupby(channel_df.index.get_level_values('Unique_ROI'))\n",
    "    for roi in channel_df.index.get_level_values('Unique_ROI').unique():\n",
    "        ROI_df = ROI_groups.get_group(roi)\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,4), sharey=True)      \n",
    "        for col, (ttype, color) in enumerate(zip(['rewarded hit','rewarded FA','unrewarded hit'],['navy','cyan','magenta'])):\n",
    "            ttype_df = ROI_df[(ROI_df.index.get_level_values('Final Outcome') == 'Tactile '+ttype) | (ROI_df.index.get_level_values('Final Outcome') == 'Auditory '+ttype)]\n",
    "            inferred = []\n",
    "            for index, rows in ttype_df.iterrows():\n",
    "                fps = 30.3 if len(rows.dropna()) == 364 else 30.54\n",
    "                if index[8] == '-':\n",
    "                    water = 4.5\n",
    "                else:\n",
    "                    if index[13] == '-':\n",
    "                        water = int(index[8])/1000 + 1\n",
    "                    else:\n",
    "                        water = int(index[13])/1000\n",
    "                inferred.append(rows.iloc[math.floor(water*fps)-30:math.floor(water*fps)+90].to_frame().reset_index().iloc[:,1:].T)\n",
    "            if len(inferred) > 0 :\n",
    "                inferred_df = pd.concat(inferred)\n",
    "                ax[col].plot(inferred_df.mean(), color=color, linewidth=3)\n",
    "                for trial, rows in inferred_df.iterrows():\n",
    "                    if rows.mean() != float(-1):\n",
    "                        ax[col].plot(rows, color='black', linewidth=1, alpha=0.5)\n",
    "                ax[col].set_title(ttype)\n",
    "                ax[col].set_xticks(np.linspace(0,129,5))\n",
    "                ax[col].set_xticklabels([str(int(x)) for x in np.linspace(-1,3,5)])\n",
    "\n",
    "        plt.suptitle(roi)\n",
    "#             fig.savefig(roi+'_EXAMPLE_traces.svg')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f385eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_behavior = []\n",
    "imaging_behavior_rates = []\n",
    "for mouse in deltaF.index.get_level_values(0).unique():\n",
    "    mouse_df = deltaF[deltaF.index.get_level_values(0) == mouse]\n",
    "    for session in mouse_df.index.get_level_values('Unique session').unique():\n",
    "        session_df = mouse_df[mouse_df.index.get_level_values('Unique session') == session]\n",
    "        protocol = session_df.index.get_level_values('Protocol')[0]\n",
    "        first_ROI = session_df.index.get_level_values('ROI').unique()[0]\n",
    "        first_ROI_df = session_df[session_df.index.get_level_values('ROI') == first_ROI]\n",
    "        if first_ROI_df.shape[0] > 30:\n",
    "            first_ROI_df = first_ROI_df.reset_index().iloc[:,:22]\n",
    "            first_ROI_df = first_ROI_df.rename({'level_0':'ID'}, axis=1)\n",
    "            first_ROI_df['Anticipatory licks'] = [x+1 for x in list(first_ROI_df['Anticipatory licks'])]\n",
    "            first_ROI_df['Response latency'] = [(float(x)/1000)-3 for x in list(first_ROI_df['Response latency'].replace({'-':np.nan}))]\n",
    "            imaging_behavior.append(first_ROI_df)\n",
    "\n",
    "            posteriors_df = pd.DataFrame(calculate_posteriors(first_ROI_df, first_ROI_df.shape[0], protocol, 'calcium')[0])\n",
    "            prop_rare = posteriors_df['reward prob']['N'] / posteriors_df['reward prob']['G']\n",
    "            hit_rate = posteriors_df['response rate']['G']\n",
    "            FA_rate = posteriors_df['response rate']['N']\n",
    "            correct = first_ROI_df[(first_ROI_df.Outcome  == 'hit') | (first_ROI_df.Outcome  == 'CR')].shape[0]\n",
    "            CP_rate = correct/first_ROI_df.shape[0]\n",
    "            FA_latency = (first_ROI_df[first_ROI_df.Outcome == 'FA']['Response latency']).mean()\n",
    "            hit_latency = (first_ROI_df[first_ROI_df.Outcome == 'hit']['Response latency']).mean()\n",
    "            FA_licks = (first_ROI_df[first_ROI_df.Outcome == 'FA']['Anticipatory licks']).mean()\n",
    "            hit_licks = (first_ROI_df[first_ROI_df.Outcome == 'hit']['Anticipatory licks']).mean()\n",
    "            norm_licks = FA_licks/hit_licks\n",
    "            FA_licks_rew = (first_ROI_df[(first_ROI_df.Outcome == 'FA') & (first_ROI_df.Water == float(1))]['Reward licks']).mean()\n",
    "            hit_licks_rew = (first_ROI_df[(first_ROI_df.Outcome == 'hit') & (first_ROI_df.Water == float(1))]['Reward licks']).mean()\n",
    "            final_df = pd.DataFrame([CP_rate, hit_rate, FA_rate, prop_rare, norm_licks, FA_licks, hit_licks, FA_licks_rew, hit_licks_rew, hit_latency, FA_latency, protocol], \n",
    "                                    index=['CP rate','Hit rate','FA rate','Rare outcome proportion','Hit/FA licks', 'Hit ant', 'FA ant', 'Hit rew','FA rew', 'Hit latency','FA latency', 'Protocol'], \n",
    "                                    columns=[mouse+'_'+session]).T\n",
    "            final_df = final_df.reset_index().set_index(['index','Protocol'])\n",
    "            imaging_behavior_rates.append(final_df)\n",
    "imaging_behavior = pd.concat(imaging_behavior)\n",
    "imaging_behavior_rates = pd.concat(imaging_behavior_rates)\n",
    "imaging_behavior_rates.index = imaging_behavior_rates.index.set_names('FOV',level=0)\n",
    "imaging_behavior_rates.to_csv('imaging_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8861563",
   "metadata": {},
   "outputs": [],
   "source": [
    "rthresh = 0\n",
    "event_thresh = 0.25\n",
    "time_thresh = 15\n",
    "plot_and_extract_correlated_ROIs(rthresh, event_thresh, time_thresh)\n",
    "correlated_ROIs = np.load('correlated_ROIs_'+str(rthresh)+'rthresh_'+str(event_thresh)+'eventthresh.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7d4215",
   "metadata": {},
   "source": [
    "# FIGURE OUT HOW TO GROUPBY WITH LATENCY/WATER TIME AS NUMERIC VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15da2c86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dtype, dtype_dict in cohort_epochs.items():\n",
    "    if dtype != 'deltaF':\n",
    "        for epoch, epoch_dict in dtype_dict.items():\n",
    "            if epoch == 'reward':\n",
    "                epoch_df = pd.concat(epoch_dict)\n",
    "                if epoch_df.shape[0] > 0:\n",
    "                    if dtype == 'pupil':\n",
    "                        for UOA_label, UOA_name in zip(['Unique_trial','Unique session'], ['single_trials','session_by_session']):\n",
    "                            pupil_dfs = {}\n",
    "                            for ttype in ['rewarded hit','rewarded FA','unrewarded hit']:\n",
    "                                ttype_df = epoch_df[(epoch_df.index.get_level_values('Final Outcome') == 'Tactile '+ttype) | (epoch_df.index.get_level_values('Final Outcome') == 'Auditory '+ttype)]\n",
    "                                ttype_df = ttype_df.max(axis=1).to_frame()\n",
    "                                UOA_groups = ttype_df.groupby(ttype_df.index.get_level_values(UOA_label))\n",
    "                                pupil_dfs[ttype] = UOA_groups.mean()\n",
    "                            pupil_df = pd.concat(pupil_dfs, axis=1)\n",
    "                            pupil_df['Protocol'] = [x.split('_')[0] for x in list(pupil_df.index)]\n",
    "                            pupil_df = pupil_df.reset_index().set_index([UOA_label,'Protocol']).droplevel(1, axis=1)\n",
    "                            pupil_df.to_csv(('_').join([epoch,'peak_pupil',UOA_name,'.csv']))\n",
    "                    elif dtype == 'events':\n",
    "                        UOA_label = 'Unique_ROI'\n",
    "                        events_dfs = {}\n",
    "                        for ttype in ['rewarded hit','rewarded FA','unrewarded hit']:\n",
    "                            ttype_df = epoch_df[(epoch_df['Final Outcome'] == 'Tactile '+ttype) | (epoch_df['Final Outcome'] == 'Auditory '+ttype)]\n",
    "                            UOA_groups = ttype_df.groupby(ttype_df[UOA_label])\n",
    "                            event_metrics = UOA_groups.mean()\n",
    "                            event_counts = UOA_groups.size().to_frame()\n",
    "                            all_deltaF = pd.concat(cohort_epochs['deltaF']['all'])\n",
    "                            ttype_deltaF = all_deltaF[(all_deltaF.index.get_level_values('Final Outcome') == 'Tactile '+ttype) | (all_deltaF.index.get_level_values('Final Outcome') == 'Auditory '+ttype)]\n",
    "                            mutual_deltaF = ttype_deltaF[ttype_deltaF.index.get_level_values('Unique_ROI').isin(event_counts.index.get_level_values('Unique_ROI').unique())]\n",
    "                            trial_counts = mutual_deltaF.groupby(mutual_deltaF.index.get_level_values('Unique_ROI')).size().to_frame()\n",
    "                            event_metrics['rate'] = list((event_counts/trial_counts)[0])\n",
    "                            display(event_metrics)\n",
    "                            break\n",
    "                break\n",
    "#                         events_dfs[ttype] = event_metrics[['ev_onset','peak','rate']]\n",
    "#                     event_df = pd.concat(events_dfs, axis=1)\n",
    "#                     event_df = event_df.swaplevel(0,1,axis=1).sort_index(level=0, axis=1)\n",
    "#                     event_df['Protocol'] = [x.split('_')[0] for x in list(event_df.index.get_level_values(UOA_label))]\n",
    "#                     event_df['Channel'] = [x.split('_')[-2] for x in list(event_df.index.get_level_values(UOA_label))]\n",
    "#                     event_df = event_df.reset_index().set_index([UOA_label,'Protocol', 'Channel'])\n",
    "#                     event_df.to_csv(('_').join([epoch,'calcium_metrics.csv']))                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403aa80a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3334775c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeb04fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348120af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac65795e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1b48c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bb3886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9fa391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbca683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279bbf7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee4f5de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36542c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d3405b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d8427de",
   "metadata": {},
   "source": [
    "## Make this previous trial, and add correlated/uncorrelated ROI label\n",
    "## Then try outcome encoding averaged over the last 10 trials for each ROI as an individual feature instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e90a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "both_channels = []\n",
    "for channel, channel_dict in all_single_trials.items():\n",
    "    channel_df = pd.concat(channel_dict)\n",
    "    channel_df = channel_df[channel_df.index.get_level_values(0) == 'all']\n",
    "    for index, rows in channe\n",
    "#     both_channels.append(channel_df)\n",
    "# both_df = pd.concat(both_channels)\n",
    "# both_df['ev_latency'] = both_df['ev_onset'] - both_df['inferred']\n",
    "# both_df.to_csv('reward_all_single_trials.csv')\n",
    "        \n",
    "#     if rows['Response latency'] isnan == True:\n",
    "#     print(type(rows['Response latency']))\n",
    "#     channel_df.to_csv(channel+'_delayed_reward_single_trial_correlations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2220c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FOV_norm_means = {}\n",
    "all_reward_events = pd.concat(all_event_rates, axis=1)\n",
    "all_reward_events\n",
    "all_reward_events = all_reward_events.replace({0:np.nan})\n",
    "for soma, soma_list in somas.items():\n",
    "    if len(soma_list) == 0:\n",
    "        all_reward_events = all_reward_events[~(all_reward_events.index.get_level_values(0).str.contains(soma))]\n",
    "    else:\n",
    "        FOV = soma_list[0]\n",
    "        all_reward_events = all_reward_events[~((all_reward_events.index.get_level_values(0).str.contains(soma)) & (all_reward_events.index.get_level_values(0).str.contains(FOV)))]\n",
    "all_reward_events = all_reward_events[~(all_reward_events.index.get_level_values(0).str.contains('RGECO_GCamP_Batch1_muji_Edis_221104_FOV3.1'))]\n",
    "\n",
    "for channel in ['Red','Green']:\n",
    "    channel_df = all_reward_events[all_reward_events.index.get_level_values(0).str.contains(channel)]\n",
    "    correlated_dfs = []\n",
    "    uncorrelated_dfs =[]\n",
    "    for index, rows in channel_df.iterrows():\n",
    "        mouse = ('_').join(index[0].split('_')[:4])\n",
    "        ROI = index[0].split(mouse)[1][1:]\n",
    "\n",
    "        if len(correlated_ROIs[mouse].keys()) > 0:\n",
    "            if ROI in correlated_ROIs[mouse].keys():\n",
    "                correlated_dfs.append(rows.to_frame().T)\n",
    "            else:\n",
    "                uncorrelated_dfs.append(rows.to_frame().T)\n",
    "        else:\n",
    "                uncorrelated_dfs.append(rows.to_frame().T)            \n",
    "    correlated_df = pd.concat(correlated_dfs)\n",
    "    correlated_df.index.names = channel_df.index.names\n",
    "    uncorrelated_df = pd.concat(uncorrelated_dfs)\n",
    "    uncorrelated_df.index.names = channel_df.index.names\n",
    "    \n",
    "    for label, df in zip(['correlated_ROIs','uncorrelated_ROIs','ALL_ROIs'], [correlated_df, uncorrelated_df, channel_df]):\n",
    "        df['FOV'] = [('_').join(x.split('_')[:-2]) for x in list(df.index.get_level_values('Final index'))]\n",
    "        df = df.reset_index().set_index(['FOV','Final index','Protocol'])\n",
    "        FOV_means = df.groupby([df.index.get_level_values('FOV'), df.index.get_level_values('Protocol')]).mean()\n",
    "        norm_type = {}\n",
    "        for ttype in FOV_means.columns:\n",
    "            norm_type[ttype] = FOV_means['rewarded hit']\n",
    "        normalizer = pd.concat(norm_type, axis=1)\n",
    "        norm_df = df.div(normalizer)\n",
    "        if label == 'ALL_ROIs':\n",
    "#             protocol_df = norm_df[(norm_df.index.get_level_values('Protocol').str.contains('dis')) | (norm_df.index.get_level_values('Protocol').str.contains('rev'))]\n",
    "            protocol_df = norm_df\n",
    "            FOV_norms = protocol_df.groupby([protocol_df.index.get_level_values('FOV'), protocol_df.index.get_level_values('Protocol')]).mean()\n",
    "            correlation_df = pd.merge(FOV_norms, imaging_behavior, left_index=True, right_index=True)\n",
    "            correlation_df = correlation_df[['rewarded FA', 'unrewarded hit', 'rewarded hit','CP rate','Hit rate','FA rate','Rare outcome proportion','Hit/FA licks']]\n",
    "            correlation_df.to_csv(channel+'_behavior_population_reward_calcium_correlation.csv')\n",
    "            df.to_csv(('_').join([label,channel,'reward_event_rate.csv']))\n",
    "            norm_df.to_csv(('_').join([label,channel,'reward_NORM_event_rate.csv']))\n",
    "        else:\n",
    "            df.to_csv(('_').join([label,str(event_thresh),channel,'reward_event_rate.csv']))\n",
    "            norm_df.to_csv(('_').join([label,str(event_thresh),channel,'reward_NORM_event_rate.csv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d316adf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'deltaF_pupil.npy' in os.listdir(cwd):\n",
    "    print('deltaF_pupil.npy file found')\n",
    "    print('deltaF_pupil.npy file uploading now...')\n",
    "    deltaF_pupil = np.load('deltaF_pupil.npy', allow_pickle=True)\n",
    "    print('finished uploading')\n",
    "\n",
    "else:\n",
    "    print('deltaF_pupil.npy file not found')\n",
    "    print('deltaF_pupil.npy file creating now...')    \n",
    "    import time\n",
    "    start = time.time()\n",
    "\n",
    "    deltaF_df = pd.concat(cohort_deltaF)\n",
    "    pupil_df = pd.concat(cohort_pupil)\n",
    "    deltaF_pupil = {}\n",
    "    mouse_groups = deltaF_df.groupby(deltaF_df.index.get_level_values(0))\n",
    "    for mouse in deltaF_df.index.get_level_values(0).unique():\n",
    "        deltaF_pupil[mouse] = {}\n",
    "        mouse_df = mouse_groups.get_group(mouse)\n",
    "        ROI_groups = mouse_df.groupby(mouse_df.index.get_level_values('Unique_ROI'))\n",
    "        mouse_correlation = {}\n",
    "\n",
    "        for i, (ROI) in enumerate(mouse_df.index.get_level_values('Unique_ROI').unique()):\n",
    "            ROI_df = ROI_groups.get_group(ROI)\n",
    "            deltaF_list = []\n",
    "            pupil_list = []\n",
    "            df_dict = {}\n",
    "            for j, (index, rows) in enumerate(ROI_df.iterrows()):\n",
    "                midx_number = np.where(np.asarray(ROI_df.index.names) == 'Unique_trial')[0][0]\n",
    "                unique_trial = index[midx_number]\n",
    "                mouse_pupil = pupil_df[pupil_df.index.get_level_values(0) == mouse]\n",
    "\n",
    "                if unique_trial in mouse_pupil.index.get_level_values('Unique_trial'):\n",
    "                    trial_pupil = np.asarray(mouse_pupil[mouse_pupil.index.get_level_values('Unique_trial') == unique_trial].iloc[0])\n",
    "                    downsampled_pupil = np.asarray([np.mean(x) for x in list(split(trial_pupil, rows.shape[0]))])\n",
    "                    trial_df = pd.DataFrame([np.asarray(rows), downsampled_pupil], index=['deltaF', 'pupil']).T\n",
    "                    df_dict[unique_trial] = trial_df\n",
    "            mouse_correlation = pd.concat(df_dict) if len(df_dict.keys()) > 0 else pd.DataFrame([], index=['deltaF', 'pupil']).T\n",
    "            deltaF_pupil[mouse][ROI] = mouse_correlation\n",
    "    pickle.dump(deltaF_pupil, open(\"deltaF_pupil.npy\", \"wb\"))\n",
    "\n",
    "    end = time.time()\n",
    "    print(end-start, 'seconds taken to create')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f66511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch, epoch_dict in cohort_epochs['pupil'].items():\n",
    "    if epoch == 'all':\n",
    "        epoch_df = pd.concat(epoch_dict).dropna(how='all')\n",
    "        dfs = []\n",
    "        for index, rows in epoch_df.iterrows():\n",
    "            water = index[12]\n",
    "            lick = index[7]\n",
    "            \n",
    "            if lick == '-':\n",
    "                water = 4500\n",
    "            else:\n",
    "                if water == '-':\n",
    "                    water = int(lick)+1000\n",
    "                else:\n",
    "                    water = int(water)\n",
    "            water_fps = math.floor(water/1000*30*30)\n",
    "            dfs.append(rows.iloc[water_fps:water_fps+1800].to_numpy())\n",
    "        df = pd.DataFrame(dfs, index=epoch_df.index, columns=list(range(900)))\n",
    "        \n",
    "        peak_df = df.max(axis=1).to_frame()\n",
    "        peak_df['Response latency'] = peak_df.index.get_level_values('Response latency')\n",
    "        peak_df['Prestim licks'] = peak_df.index.get_level_values('Prestim licks')\n",
    "        peak_df['Anticipatory licks'] = peak_df.index.get_level_values('Anticipatory licks')\n",
    "        peak_df['Reward licks'] = peak_df.index.get_level_values(' Reward licks')\n",
    "        peak_df = peak_df.droplevel(['Response latency','Prestim licks','Anticipatory licks',' Reward licks'])\n",
    "        peak_df = peak_df.rename({0:'Peak dilation'}, axis=1)\n",
    "\n",
    "        ttype_peaks = []\n",
    "        for t in ['rewarded hit', 'unrewarded hit', 'rewarded FA', 'unrewarded FA']:\n",
    "            if t in ['rewarded hit','rewarded FA']:\n",
    "                ttype_peak = peak_df[(peak_df.index.get_level_values('Final Outcome') == 'Tactile '+t) | (peak_df.index.get_level_values('Final Outcome') == 'Auditory '+t)].T\n",
    "            else:    \n",
    "                ttype_peak = peak_df[peak_df.index.get_level_values('Final Outcome').str.contains(t)].T\n",
    "            ttype_peak.index = pd.MultiIndex.from_tuples((x,y) for x,y in zip(ttype_peak.index, [t]*ttype_peak.shape[0]))\n",
    "            ttype_peak = ttype_peak.T.droplevel('Final Outcome')\n",
    "            ttype_peaks.append(ttype_peak)\n",
    "        ttype_peak_df = pd.concat(ttype_peaks, axis=1).sort_index(level=0, axis=1)\n",
    "    ttype_peak_df.to_csv('delayed_reward_SINGLE_TRIAL_PUPIL.csv')\n",
    "\n",
    "    sesh_by_sesh = ttype_peak_df.groupby([ttype_peak_df.index.get_level_values(0), ttype_peak_df.index.get_level_values('Unique session'), ttype_peak_df.index.get_level_values('Protocol')]).mean()\n",
    "    sesh_by_sesh['sesh'] = sesh_by_sesh.index.get_level_values(0) + '_' + sesh_by_sesh.index.get_level_values('Unique session')\n",
    "    sesh_by_sesh.to_csv('delayed_reward_sesh_by_sesh_PUPIL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c646e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch, epoch_dict in cohort_epochs['events'].items():\n",
    "    if epoch == 'all':\n",
    "        epoch_df = pd.concat(epoch_dict)\n",
    "        \n",
    "        for soma, soma_list in somas.items():\n",
    "            if len(soma_list) == 0:\n",
    "                epoch_df = epoch_df[epoch_df.index.get_level_values(0) != soma]\n",
    "            else:\n",
    "                FOV = soma_list[0]\n",
    "                epoch_df = epoch_df[~((epoch_df.index.get_level_values(0).str.contains(soma)) & (epoch_df['FOV'].str.contains(FOV)))]\n",
    "        \n",
    "\n",
    "        deltaF_df = pd.concat(cohort_epochs['deltaF'][epoch])\n",
    "        deltaF_dfs = []\n",
    "        for index, rows in deltaF_df.iterrows():\n",
    "            water = index[12]\n",
    "            lick = index[7]\n",
    "\n",
    "            if lick == '-':\n",
    "                water = 4500\n",
    "            else:\n",
    "                if water == '-':\n",
    "                    water = int(lick)+1000\n",
    "                else:\n",
    "                    water = int(water)\n",
    "            water_fps = math.floor(water/1000*30.3)\n",
    "            deltaF_dfs.append(rows.iloc[water_fps:water_fps+30].to_numpy())\n",
    "        deltaF_df = pd.DataFrame(deltaF_dfs, index=deltaF_df.index, columns=list(range(30)))\n",
    "        \n",
    "        for protocol in ['Ndet','Ndis', 'Nrev']:\n",
    "            plt.figure()\n",
    "            legends = []\n",
    "            for t, c in zip(['rewarded hit', 'unrewarded hit', 'rewarded FA', 'unrewarded FA'], ['navy','magenta','cyan','orange']):\n",
    "                ttype_df = deltaF_df[(deltaF_df.index.get_level_values('Final Outcome') == 'Tactile '+t) | (deltaF_df.index.get_level_values('Final Outcome') == 'Auditory '+t)]\n",
    "                ttype_df = ttype_df[ttype_df.index.get_level_values('Protocol') == protocol]\n",
    "                ttype_df = ttype_df[ttype_df.index.get_level_values('Channel') == 'Red']\n",
    "                plt.plot(list(range(30)), ttype_df.mean(), color=c)\n",
    "                plt.fill_between(list(range(30)), ttype_df.mean()-ttype_df.sem(), ttype_df.mean()+ttype_df.sem(), color=c, alpha=0.5)\n",
    "                legends.append(t)\n",
    "                legends.append(t)\n",
    "            plt.legend(legends)\n",
    "            plt.suptitle(protocol)\n",
    "\n",
    "\n",
    "#         correlated_dfs = []\n",
    "#         for index, rows in epoch_df.iterrows():\n",
    "#             mouse = index[0]\n",
    "#             ROI = rows['Unique_ROI']\n",
    "\n",
    "#             if len(correlated_ROIs[mouse].keys()) > 0:\n",
    "#                 if ROI in correlated_ROIs[mouse].keys():\n",
    "#                     correlated_dfs.append(rows.to_frame().T)\n",
    "\n",
    "#         if len(correlated_dfs) == 0:\n",
    "#             correlated_df = epoch_df\n",
    "#         else:\n",
    "#             correlated_df = pd.concat(correlated_dfs)\n",
    "#             correlated_df.index.names = correlated_df.index.names\n",
    "\n",
    "#         for label, df in zip(['ALL_ROIs','correlated_ROIs'],[epoch_df, correlated_df]):\n",
    "#             if label == 'ALL_ROIs':\n",
    "#                 epoch_event_rates = []\n",
    "#                 epoch_event_metrics_list = []\n",
    "#                 plt.figure()\n",
    "#                 legends = []\n",
    "#                 for t in ['rewarded hit', 'unrewarded hit', 'rewarded FA', 'unrewarded FA']:\n",
    "#                     ttype_events = df[(df['Final Outcome'] == 'Tactile '+t) | (df['Final Outcome'] == 'Auditory '+t)]\n",
    "#                     ROI_event_count = ttype_events.groupby([ttype_events.index.get_level_values(0), 'Unique_ROI', 'Protocol']).size()\n",
    "#                     plt.hist(ROI_event_count, alpha=0.5)\n",
    "#                     legends.append(t)\n",
    "#                 plt.legend(legends)\n",
    "#                 ROI_deltaF_df = deltaF_df[deltaF_df.index.get_level_values('Unique_ROI').isin(list(ROI_event_count.index.get_level_values('Unique_ROI')))]\n",
    "#                 ttype_deltaF = ROI_deltaF_df[ROI_deltaF_df.index.get_level_values('Final Outcome').str.contains(t)]\n",
    "#                 ROI_trial_count = ttype_deltaF.groupby([ttype_deltaF.index.get_level_values(0), ttype_deltaF.index.get_level_values('Unique_ROI'), ttype_deltaF.index.get_level_values('Protocol')]).size()\n",
    "#                 ROI_event_rate = ROI_event_count / ROI_trial_count\n",
    "#                 ROI_event_rate_df = pd.DataFrame(ROI_event_rate.values, index=ROI_event_rate.index, columns=[t])\n",
    "#                 epoch_event_rates.append(ROI_event_rate_df)\n",
    "#                 epoch_event_means = ttype_events.groupby([ttype_events.index.get_level_values(0), 'Unique_ROI', 'Final Outcome','Protocol']).mean()\n",
    "\n",
    "#                 outcome_df = ttype_events.groupby([ttype_events.index.get_level_values(0),ttype_events['Unique_ROI'], ttype_events['Protocol']]).mean().T.reset_index()\n",
    "#                 outcome_df.index = pd.MultiIndex.from_tuples([(x,y) for x,y in zip(outcome_df['index'], [t]*outcome_df.shape[0])])\n",
    "#                 outcome_df = outcome_df.T\n",
    "#                 epoch_event_metrics_list.append(outcome_df)\n",
    "#             epoch_event_metrics = pd.concat(epoch_event_metrics_list, axis=1).T\n",
    "\n",
    "#             epoch_event_metric_list = []\n",
    "#             for metric in ['response latency', 'Prestim licks', 'Anticipatory licks', 'Reward licks', 'Stimulus', 'peak', 'ev_onset', 'peak_time', 'integral']:\n",
    "#                 metric_df = epoch_event_metrics[epoch_event_metrics.index.get_level_values(0) == metric]\n",
    "#                 epoch_event_metric_list.append(metric_df)\n",
    "#             epoch_event_metrics = pd.concat(epoch_event_metric_list).T\n",
    "#             epoch_event_rate = pd.concat(epoch_event_rates, axis=1)\n",
    "\n",
    "#             for channel in ['Red','Green']:\n",
    "#                 channel_epoch_event_rate = epoch_event_rate[epoch_event_rate.index.get_level_values('Unique_ROI').str.contains(channel)]\n",
    "#                 channel_epoch_event_metrics = epoch_event_metrics[epoch_event_metrics.index.get_level_values('Unique_ROI').str.contains(channel)]\n",
    "\n",
    "#                 channel_epoch_event_rate.to_csv(('_').join([label,channel,epoch,'event_rate.csv']))\n",
    "#                 channel_epoch_event_metrics.to_csv(('_').join([label,channel,epoch,'event_metrics.csv']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f35c566",
   "metadata": {},
   "source": [
    "## Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247fe390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pupil(data, epochs, protocols, outcomes, plottype, trials, event_epochs=None):\n",
    "    data = data['pupil']\n",
    "    if type(epochs) == str:\n",
    "        if epochs == 'all':\n",
    "            epochs = data.keys()\n",
    "    else:   \n",
    "        epochs = epochs\n",
    "        \n",
    "    for epoch, epoch_dict in data.items():\n",
    "        if epoch in epochs:\n",
    "            epoch_df = pd.concat(epoch_dict)\n",
    "            epoch_df = epoch_df[epoch_df.index.get_level_values('Stimulus') != float(3)]   \n",
    "            \n",
    "            if type(protocols) == str:\n",
    "                if protocols == 'all':\n",
    "                    protocols = ['N','E'] + list(epoch_df.index.get_level_values('Protocol').unique())\n",
    "            else:\n",
    "                protocols = protocols\n",
    "            \n",
    "            for protocol in protocols:\n",
    "                view_outcomes = []\n",
    "                labels = []\n",
    "                \n",
    "                for outcome in outcomes:\n",
    "                    if (outcomes == ['FA', 'hit']) | (outcomes == ['hit', 'FA']):\n",
    "                        for label, reward in zip(['rewarded', 'unrewarded'],[float(1), float(0)]):\n",
    "                            rew_df = epoch_df[epoch_df.index.get_level_values('Water') == reward]\n",
    "                            out_df = rew_df[rew_df.index.get_level_values('Final Outcome').str.contains(outcome)]\n",
    "                            view_outcomes.append(out_df)\n",
    "                            labels.append(label+' '+outcome)\n",
    "                    else:\n",
    "                            out_df = epoch_df[epoch_df.index.get_level_values('Final Outcome').str.contains(outcome)]\n",
    "                            view_outcomes.append(out_df)\n",
    "                            labels.append(outcome)                            \n",
    "                \n",
    "                n = len(view_outcomes)\n",
    "                fig, ax = plt.subplots(nrows=1, ncols=n, figsize=(5*n,3), sharey=True)\n",
    "                if plottype == 'trials':\n",
    "                    color = cm.rainbow(np.linspace(0, 1, n)) \n",
    "                    for col, (outcome_df, color, label) in enumerate(zip(view_outcomes, color, labels)):\n",
    "                        outcome_df = outcome_df[outcome_df.index.get_level_values('Protocol').str.contains(protocol)]\n",
    "                        \n",
    "                        if trials == 'events':\n",
    "                            outcome_df = get_event_trials(outcome_df, 'pupil', event_epochs)\n",
    "                        else:\n",
    "                            outcome_df = outcome_df\n",
    "                        \n",
    "                        nmice = len(outcome_df.index.get_level_values(0).unique())\n",
    "                        nsessions = len(outcome_df.index.get_level_values('Unique session').unique())\n",
    "                        mouse_counts = {}\n",
    "                        for mouse in outcome_df.index.get_level_values(0).unique():\n",
    "                            mouse_counts[mouse] = len(outcome_df[outcome_df.index.get_level_values(0) == mouse].index.get_level_values('Unique_trial').unique())\n",
    "                            \n",
    "                        unique = outcome_df.groupby(outcome_df.index.get_level_values('Unique_trial')).mean()\n",
    "                        ntrials = unique.shape[0]\n",
    "                        mean = unique.mean()\n",
    "                        sem = unique.sem()\n",
    "                        ax[col].plot(mean, color=color)\n",
    "                        ax[col].fill_between(x=list(range(unique.shape[1])), y1=mean-sem, y2=mean+sem, color=color, alpha=0.5)\n",
    "                        if epoch == 'all':\n",
    "                            ax[col].set_xticks(np.linspace(0,unique.shape[1],13))\n",
    "                            ax[col].set_xticklabels([int(x) for x in np.linspace(0,12,13)])      \n",
    "                        else:\n",
    "                            ax[col].set_xticks(np.linspace(0,unique.shape[1],11))\n",
    "                            ax[col].set_xticklabels([str(round(x,1)) for x in np.linspace(0,1,11)])\n",
    "                        \n",
    "                        title = str(nsessions)+' sessions/'+str(ntrials)+' trials \\n '                     \n",
    "                        for i, (key, value) in enumerate(mouse_counts.items()):\n",
    "                            title += ' \\n '+key+': '+str(value)+' trials'\n",
    "                        ax[col].set_title(title)\n",
    "                        ax[col].legend([label])\n",
    "                        \n",
    "                else:\n",
    "                    legends = []\n",
    "                    for col, (outcome_df, label) in enumerate(zip(view_outcomes, labels)):\n",
    "                        outcome_df = outcome_df[outcome_df.index.get_level_values('Protocol').str.contains(protocol)]\n",
    "                        \n",
    "                        if trials == 'events':\n",
    "                            outcome_df = get_event_trials(outcome_df, 'pupil', event_epochs)\n",
    "                        else:\n",
    "                            outcome_df = outcome_df\n",
    "                            \n",
    "                        nmice = len(list(outcome_df.index.get_level_values(0).unique()))\n",
    "                        color = cm.rainbow(np.linspace(0,1,nmice))                        \n",
    "                        unique = outcome_df.groupby(outcome_df.index.get_level_values(0)).mean() \n",
    "                        \n",
    "                        for j, ((color), (index, rows)) in enumerate(zip(color, unique.iterrows())):\n",
    "                            ax[col].plot(rows, color=ID_colors[index])\n",
    "                            if epoch == 'all':\n",
    "                                ax[col].set_xticks(np.linspace(0,unique.shape[1],13))\n",
    "                                ax[col].set_xticklabels([int(x) for x in np.linspace(0,12,13)])      \n",
    "                            else:\n",
    "                                ax[col].set_xticks(np.linspace(0,unique.shape[1],11))\n",
    "                                ax[col].set_xticklabels([str(round(x,1)) for x in np.linspace(0,1,11)])                \n",
    "                            ax[col].set_title(label)\n",
    "                            legends.append(index)\n",
    "                        ax[col].legend(legends, prop={'size': 6})\n",
    "                if trials == 'all':\n",
    "                    plt.suptitle(protocol+' '+epoch+' epoch (Pupil) using all trials', fontsize=25, y=1.5)\n",
    "                else:\n",
    "                    plt.suptitle(protocol+' '+epoch+' epoch (Pupil) using only trials with '+event_epochs+' events', fontsize=25, y=1.5)\n",
    "                plt.ylim(0.94,1.2)\n",
    "                fig.savefig(protocol+'_pupil.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59fb767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_calcium(data, channel, epochs, protocols, outcomes, plottype, trials, event_epochs=None):\n",
    "    data = data['deltaF']\n",
    "\n",
    "    if type(epochs) == str:\n",
    "        if epochs == 'all':\n",
    "            data.keys()\n",
    "    else:   \n",
    "        epochs = epochs\n",
    "        \n",
    "    for epoch, epoch_dict in data.items():\n",
    "        if epoch in epochs:\n",
    "            epoch_df = pd.concat(epoch_dict)\n",
    "            epoch_df = epoch_df[epoch_df.index.get_level_values('Stimulus') != float(3)]  \n",
    "            \n",
    "            groups = epoch_df.groupby(epoch_df.index.get_level_values(0))\n",
    "            for group in epoch_df.index.get_level_values(0).unique():\n",
    "                group_df = groups.get_group(group)\n",
    "            epoch_df = epoch_df[epoch_df.index.get_level_values('Channel') == channel]\n",
    "            \n",
    "            if channel == 'Green':\n",
    "                epoch_df = epoch_df\n",
    "            else:\n",
    "                for soma, soma_list in somas.items():\n",
    "                    if len(soma_list) == 0:\n",
    "                        epoch_df = epoch_df[epoch_df.index.get_level_values(0) != soma]\n",
    "                    else:\n",
    "                        FOV = soma_list[0]\n",
    "                        epoch_df = epoch_df[~((epoch_df.index.get_level_values(0).str.contains(soma)) & (epoch_df.index.get_level_values('FOV').str.contains(FOV)))]\n",
    "            \n",
    "            if type(protocols) == str:\n",
    "                if protocols == 'all':\n",
    "                    protocols = ['N','E'] + list(epoch_df.index.get_level_values('Protocol').unique())\n",
    "            else:\n",
    "                protocols = protocols\n",
    "            \n",
    "            for protocol in protocols:\n",
    "                view_outcomes = []\n",
    "                labels = []\n",
    "                for outcome in outcomes:\n",
    "                    if (outcomes == ['FA', 'hit']) | (outcomes == ['hit', 'FA']):\n",
    "                        if epoch in ['reward', 'ITI', 'delayed_reward', 'all']:\n",
    "                            for label, reward in zip(['rewarded', 'unrewarded'],[float(1), float(0)]):\n",
    "                                rew_df = epoch_df[epoch_df.index.get_level_values('Water') == reward]\n",
    "                                out_df = rew_df[rew_df.index.get_level_values('Final Outcome').str.contains(outcome)]\n",
    "                                view_outcomes.append(out_df)\n",
    "                                labels.append(label+' '+outcome)\n",
    "                        else:\n",
    "                            out_df = epoch_df[epoch_df.index.get_level_values('Final Outcome').str.contains(outcome)]\n",
    "                            view_outcomes.append(out_df)\n",
    "                            labels.append(outcome)     \n",
    "                    elif outcome == 'rewarded':\n",
    "                        out_df = epoch_df[epoch_df.index.get_level_values('Water') == float(1)]\n",
    "                        view_outcomes.append(out_df)\n",
    "                        labels.append(outcome)   \n",
    "                    elif outcome == 'unrewarded':                        \n",
    "                        out_df = epoch_df[epoch_df.index.get_level_values('Water') == float(0)]\n",
    "                        view_outcomes.append(out_df)\n",
    "                        labels.append(outcome)                           \n",
    "                    else:\n",
    "                            out_df = epoch_df[epoch_df.index.get_level_values('Final Outcome').str.contains(outcome)]\n",
    "                            view_outcomes.append(out_df)\n",
    "                            labels.append(outcome)                   \n",
    "                n = len(view_outcomes)\n",
    "                fig, ax = plt.subplots(nrows=1, ncols=n, figsize=(5*n,3), sharey=True)\n",
    "                if plottype == 'ROIs':\n",
    "                    color = cm.rainbow(np.linspace(0, 1, n)) \n",
    "                    for col, (outcome_df, color, label) in enumerate(zip(view_outcomes, color, labels)):\n",
    "                        if protocol =='E2':\n",
    "                            outcome_df = outcome_df[(outcome_df.index.get_level_values('Protocol') == 'Edis') | (outcome_df.index.get_level_values('Protocol') == 'Erev')]\n",
    "                        elif protocol =='N2':\n",
    "                            outcome_df = outcome_df[(outcome_df.index.get_level_values('Protocol') == 'Ndis') | (outcome_df.index.get_level_values('Protocol') == 'Nrev')]\n",
    "                        elif protocol == 'dynamic':\n",
    "                            outcome_df = outcome_df          \n",
    "                        elif protocol == 'stable':\n",
    "                            outcome_df = outcome_df\n",
    "                        else:\n",
    "                            outcome_df = outcome_df[outcome_df.index.get_level_values('Protocol').str.contains(protocol)]\n",
    "                        \n",
    "#                         if protocol == 'dynamic':\n",
    "#                             outcome_dfs = []\n",
    "#                             sessions = outcome_df.groupby(outcome_df.index.get_level_values('Unique session'))\n",
    "#                             for sesh in outcome_df.index.get_level_values('Unique session').unique():\n",
    "#                                 shortened_sesh = sesh.split('FOV')[0][:-1]\n",
    "#                                 sesh_df = sessions.get_group(sesh)\n",
    "#                                 check_ID = sesh_df.index.get_level_values(0)[0]\n",
    "#                                 for dysesh in short_term_strategy:\n",
    "#                                     if (check_ID in dysesh) & (shortened_sesh in dysesh) & ('PUPIL' not in dysesh):\n",
    "#                                         outcome_dfs.append(sesh_df)\n",
    "#                             outcome_df = pd.concat(outcome_dfs)\n",
    "#                         elif protocol == 'stable':\n",
    "#                             dynamic_seshes = []\n",
    "#                             sessions = outcome_df.groupby(outcome_df.index.get_level_values('Unique session'))\n",
    "#                             for sesh in outcome_df.index.get_level_values('Unique session').unique():\n",
    "#                                 shortened_sesh = sesh.split('FOV')[0][:-1]\n",
    "#                                 sesh_df = sessions.get_group(sesh)\n",
    "#                                 check_ID = sesh_df.index.get_level_values(0)[0]\n",
    "#                                 for dysesh in short_term_strategy:\n",
    "#                                     if (check_ID in dysesh) & (shortened_sesh in dysesh) & ('PUPIL' not in dysesh):\n",
    "#                                         dynamic_seshes.append(sesh)\n",
    "\n",
    "#                             outcome_dfs = []\n",
    "#                             for sesh in outcome_df.index.get_level_values('Unique session').unique():\n",
    "#                                 sesh_df = sessions.get_group(sesh)\n",
    "#                                 if sesh in dynamic_seshes:\n",
    "#                                     None\n",
    "#                                 else:\n",
    "#                                     outcome_dfs.append(sesh_df)\n",
    "#                             outcome_df = pd.concat(outcome_dfs)\n",
    "#                         else:\n",
    "#                             outcome_df = outcome_df  \n",
    "                            \n",
    "                        if trials == 'events':\n",
    "                            outcome_df = get_event_trials(outcome_df, 'deltaF', event_epochs)\n",
    "                        else:\n",
    "                            outcome_df = outcome_df\n",
    "                        \n",
    "                        mouse_counts = {}\n",
    "                        \n",
    "                        for mouse in outcome_df.index.get_level_values(0).unique():\n",
    "                            mouse_counts[mouse] = len(outcome_df[outcome_df.index.get_level_values(0) == mouse].index.get_level_values('Unique_ROI').unique())\n",
    "                            \n",
    "                        nmice = len(outcome_df.index.get_level_values(0).unique())\n",
    "                        nsessions = len(outcome_df.index.get_level_values('Unique session').unique())\n",
    "                        \n",
    "                        unique = outcome_df.groupby(outcome_df.index.get_level_values('Unique_ROI')).mean()\n",
    "                        nROIs = unique.shape[0]\n",
    "                        mean = unique.mean()\n",
    "                        sem = unique.sem()\n",
    "                        ax[col].plot(mean, color=color)\n",
    "                        ax[col].fill_between(x=list(range(unique.shape[1])), y1=mean-sem, y2=mean+sem, color=color, alpha=0.5)\n",
    "                        \n",
    "                        if epoch == 'all':\n",
    "                            ax[col].set_xticks(np.linspace(0,unique.shape[1],13))\n",
    "                            ax[col].set_xticklabels([int(x) for x in np.linspace(0,12,13)])      \n",
    "                        else:\n",
    "                            ax[col].set_xticks(np.linspace(0,unique.shape[1],11))\n",
    "                            ax[col].set_xticklabels([str(round(x,1)) for x in np.linspace(0,1,11)])\n",
    "                        title = str(nsessions)+' sessions/'+str(nROIs)+' ROIs \\n '\n",
    "                        \n",
    "                        for i, (key, value) in enumerate(mouse_counts.items()):\n",
    "                            title += ' \\n '+key+': '+str(value)+' ROIs'\n",
    "                        ax[col].set_title(title)\n",
    "                        ax[col].legend([label])\n",
    "                elif plottype == 'mice':\n",
    "                    legends = []\n",
    "                    for col, (outcome_df, label) in enumerate(zip(view_outcomes, labels)):\n",
    "                        if protocol =='E2':\n",
    "                            outcome_df = outcome_df[(outcome_df.index.get_level_values('Protocol') == 'Edis') | (outcome_df.index.get_level_values('Protocol') == 'Erev')]\n",
    "                        elif protocol =='N2':\n",
    "                            outcome_df = outcome_df[(outcome_df.index.get_level_values('Protocol') == 'Ndis') | (outcome_df.index.get_level_values('Protocol') == 'Nrev')]\n",
    "                        else:\n",
    "                            outcome_df = outcome_df[outcome_df.index.get_level_values('Protocol').str.contains(protocol)]                        \n",
    "                        \n",
    "                        if trials == 'events':\n",
    "                            outcome_df = get_event_trials(outcome_df, 'deltaF', event_epochs)\n",
    "                        else:\n",
    "                            outcome_df = outcome_df\n",
    "                            \n",
    "                        nmice = len(list(outcome_df.index.get_level_values(0).unique()))\n",
    "                        color = cm.rainbow(np.linspace(0,1,nmice))                        \n",
    "                        unique = outcome_df.groupby(outcome_df.index.get_level_values(0)).mean() \n",
    "                        \n",
    "                        for j, ((color), (index, rows)) in enumerate(zip(color, unique.iterrows())):\n",
    "                            ax[col].plot(rows, color=ID_colors[index])\n",
    "                            if epoch == 'all':\n",
    "                                ax[col].set_xticks(np.linspace(0,unique.shape[1],13))\n",
    "                                ax[col].set_xticklabels([int(x) for x in np.linspace(0,12,13)])      \n",
    "                            else:\n",
    "                                ax[col].set_xticks(np.linspace(0,unique.shape[1],11))\n",
    "                                ax[col].set_xticklabels([str(round(x,1)) for x in np.linspace(0,1,11)])              \n",
    "                            ax[col].set_title(label)\n",
    "                            legends.append(index)\n",
    "                        ax[col].legend(legends, prop={'size': 6})\n",
    "                else:\n",
    "                    color = cm.rainbow(np.linspace(0, 1, n)) \n",
    "                    for col, (uncorrelated_df, color, label) in enumerate(zip(view_outcomes, color, labels)):\n",
    "                        if protocol =='E2':\n",
    "                            uncorrelated_df = uncorrelated_df[(uncorrelated_df.index.get_level_values('Protocol') == 'Edis') | (uncorrelated_df.index.get_level_values('Protocol') == 'Erev')]\n",
    "                        elif protocol =='N2':\n",
    "                            uncorrelated_df = uncorrelated_df[(uncorrelated_df.index.get_level_values('Protocol') == 'Ndis') | (uncorrelated_df.index.get_level_values('Protocol') == 'Nrev')]\n",
    "                        elif protocol == 'dynamic':\n",
    "                            uncorrelated_df = uncorrelated_df          \n",
    "                        elif protocol == 'stable':\n",
    "                            uncorrelated_df = uncorrelated_df\n",
    "                        else:\n",
    "                            uncorrelated_df = uncorrelated_df[uncorrelated_df.index.get_level_values('Protocol').str.contains(protocol)]\n",
    "                        \n",
    "#                         if protocol == 'dynamic':\n",
    "#                             uncorrelated_dfs = []\n",
    "#                             sessions = uncorrelated_df.groupby(uncorrelated_df.index.get_level_values('Unique session'))\n",
    "#                             for sesh in uncorrelated_df.index.get_level_values('Unique session').unique():\n",
    "#                                 shortened_sesh = sesh.split('FOV')[0][:-1]\n",
    "#                                 sesh_df = sessions.get_group(sesh)\n",
    "#                                 check_ID = sesh_df.index.get_level_values(0)[0]\n",
    "#                                 for dysesh in short_term_strategy:\n",
    "#                                     if (check_ID in dysesh) & (shortened_sesh in dysesh) & ('PUPIL' not in dysesh):\n",
    "#                                         uncorrelated_dfs.append(sesh_df)\n",
    "#                             uncorrelated_df = pd.concat(uncorrelated_dfs)\n",
    "#                         elif protocol == 'stable':\n",
    "#                             dynamic_seshes = []\n",
    "#                             sessions = uncorrelated_df.groupby(uncorrelated_df.index.get_level_values('Unique session'))\n",
    "#                             for sesh in uncorrelated_df.index.get_level_values('Unique session').unique():\n",
    "#                                 shortened_sesh = sesh.split('FOV')[0][:-1]\n",
    "#                                 sesh_df = sessions.get_group(sesh)\n",
    "#                                 check_ID = sesh_df.index.get_level_values(0)[0]\n",
    "#                                 for dysesh in short_term_strategy:\n",
    "#                                     if (check_ID in dysesh) & (shortened_sesh in dysesh) & ('PUPIL' not in dysesh):\n",
    "#                                         dynamic_seshes.append(sesh)\n",
    "\n",
    "#                             uncorrelated_dfs = []\n",
    "#                             for sesh in uncorrelated_df.index.get_level_values('Unique session').unique():\n",
    "#                                 sesh_df = sessions.get_group(sesh)\n",
    "#                                 if sesh in dynamic_seshes:\n",
    "#                                     None\n",
    "#                                 else:\n",
    "#                                     uncorrelated_dfs.append(sesh_df)\n",
    "#                             uncorrelated_df = pd.concat(uncorrelated_dfs)\n",
    "#                         else:\n",
    "#                             uncorrelated_df = uncorrelated_df                         \n",
    "                        \n",
    "                        outcome_dfs = []\n",
    "                        for index, rows in uncorrelated_df.iterrows():\n",
    "                            mouse = index[0]\n",
    "                            ROI = index[19]\n",
    "                            \n",
    "                            if len(correlated_ROIs[mouse].keys()) > 0:\n",
    "                                if ROI in correlated_ROIs[mouse].keys():\n",
    "                                    outcome_dfs.append(rows.to_frame().T)\n",
    "                        \n",
    "                        if len(outcome_dfs) == 0:\n",
    "                            None\n",
    "                        else:\n",
    "                            outcome_df = pd.concat(outcome_dfs)\n",
    "                            outcome_df.index.names = uncorrelated_df.index.names\n",
    "\n",
    "                            if trials == 'events':\n",
    "                                outcome_df = get_event_trials(outcome_df, 'deltaF', event_epochs)\n",
    "                            else:\n",
    "                                outcome_df = outcome_df\n",
    "\n",
    "                            mouse_counts = {}\n",
    "\n",
    "                            for mouse in outcome_df.index.get_level_values(0).unique():\n",
    "                                mouse_counts[mouse] = len(outcome_df[outcome_df.index.get_level_values(0) == mouse].index.get_level_values('Unique_ROI').unique())\n",
    "\n",
    "                            nmice = len(outcome_df.index.get_level_values(0).unique())\n",
    "                            nsessions = len(outcome_df.index.get_level_values('Unique session').unique())\n",
    "\n",
    "                            unique = outcome_df.groupby(outcome_df.index.get_level_values('Unique_ROI')).mean()\n",
    "                            nROIs = unique.shape[0]\n",
    "                            mean = unique.mean()\n",
    "                            sem = unique.sem()\n",
    "                            ax[col].plot(mean, color=color)\n",
    "                            ax[col].fill_between(x=list(range(unique.shape[1])), y1=mean-sem, y2=mean+sem, color=color, alpha=0.5)\n",
    "\n",
    "                            if epoch == 'all':\n",
    "                                ax[col].set_xticks(np.linspace(0,unique.shape[1],13))\n",
    "                                ax[col].set_xticklabels([int(x) for x in np.linspace(0,12,13)])      \n",
    "                            else:\n",
    "                                ax[col].set_xticks(np.linspace(0,unique.shape[1],11))\n",
    "                                ax[col].set_xticklabels([str(round(x,1)) for x in np.linspace(0,1,11)])\n",
    "                            title = str(nsessions)+' sessions/'+str(nROIs)+' ROIs \\n '\n",
    "\n",
    "                            for i, (key, value) in enumerate(mouse_counts.items()):\n",
    "                                title += ' \\n '+key+': '+str(value)+' ROIs'\n",
    "                            ax[col].set_title(title)\n",
    "                            ax[col].legend([label])                    \n",
    "                if trials == 'all':\n",
    "                    if plottype == 'ROIs':\n",
    "                        plt.suptitle(protocol+' '+epoch+' epoch ('+channel+') using all trials and all ROIs', fontsize=25, y=1.5)\n",
    "                    elif plottype == 'correlated_ROIs':\n",
    "                        plt.suptitle(protocol+' '+epoch+' epoch ('+channel+') using all trials and correlated ROIs only', fontsize=25, y=1.5)                        \n",
    "                else:\n",
    "                    if plottype == 'ROIs':\n",
    "                        plt.suptitle(protocol+' '+epoch+' epoch ('+channel+') using only trials with '+event_epochs+' events and all ROIs', fontsize=25, y=1.5)\n",
    "                    elif plottype == 'correlated_ROIs':\n",
    "                        plt.suptitle(protocol+' '+epoch+' epoch ('+channel+') using only trials with '+event_epochs+' events and correlated ROIs only', fontsize=25, y=1.5)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ad1ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_trials(data, dtype, epoch):\n",
    "    events = pd.concat(cohort_epochs['events'][epoch])\n",
    "    events = events.droplevel(1)\n",
    "    \n",
    "    if dtype == 'pupil':\n",
    "        events['Date'] = [int(x) for x in list(events['Date'])]\n",
    "        IDs = pd.DataFrame([events.index], index=['mouse_ID']).T\n",
    "        midx = events.iloc[:,0:19].reset_index().iloc[:,1:]\n",
    "        final_outcomes = events['Final Outcome'].to_frame().reset_index().iloc[:,1:]\n",
    "        new_midx = pd.concat([IDs, midx, final_outcomes], axis=1)\n",
    "        events.index = pd.MultiIndex.from_tuples(tuple(np.asarray(new_midx)))\n",
    "        events = events.droplevel([6,19])\n",
    "    else:      \n",
    "        IDs = pd.DataFrame([events.index], index=['mouse_ID']).T\n",
    "        midx = events.iloc[:,0:19].reset_index().iloc[:,1:]\n",
    "        final_outcomes = events['Final Outcome'].to_frame().reset_index().iloc[:,1:]\n",
    "        new_midx = pd.concat([IDs, midx, final_outcomes], axis=1)\n",
    "        events.index = pd.MultiIndex.from_tuples(tuple(np.asarray(new_midx)))\n",
    "    events.index.names = pd.concat(cohort_epochs[dtype]['reward']).index.names \n",
    "    idx = data.index.intersection(events.index)\n",
    "    event_trials = data.loc[idx]\n",
    "    \n",
    "    return event_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e7bdee",
   "metadata": {},
   "source": [
    "## Time to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1654bfda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot_calcium(cohort_epochs, channel='Red', epochs=['all'] ,protocols=['Ndis', 'Nrev', 'Edis', 'Erev'], outcomes=['hit','FA'], plottype='correlated_ROIs', trials='all', event_epochs='reward')\n",
    "# plot_calcium(cohort_epochs, channel='Red', epochs=['all'] ,protocols=['Ndis','Edis'], outcomes=['hit','FA'], plottype='ROIs', trials='all', event_epochs='reward')\n",
    "plot_calcium(cohort_epochs, channel='Red', epochs=['all'] ,protocols=['N2','E2'], outcomes=['rewarded','unrewarded'], plottype='ROIs', trials='all', event_epochs='reward')\n",
    "plot_calcium(cohort_epochs, channel='Red', epochs=['all'] ,protocols=['N2','E2'], outcomes=['rewarded','unrewarded'], plottype='correlated_ROIs', trials='all', event_epochs='reward')\n",
    "\n",
    "# plot_calcium(cohort_epochs, channel='Green', epochs=['all'] ,protocols=['N','E'], outcomes=['hit','FA'], plottype='ROIs', trials='all', event_epochs='evnts')\n",
    "# plot_calcium(cohort_epochs, channel='Red', epochs=['all'] ,protocols=['N'], outcomes=['hit','FA'], plottype='ROIs', trials='events', event_epochs='ITI')\n",
    "# plot_calcium(cohort_epochs, channel='Red', epochs=['all'] ,protocols=['N'], outcomes=['hit','FA'], plottype='correlated_ROIs', trials='all', event_epochs='ITI')\n",
    "# plot_pupil(cohort_epochs, epochs=['ITI'] ,protocols=['Ndet','Edet','Ndis','Edis','Nrev','Erev'], outcomes=['hit','FA'], plottype='trials', trials='all', event_epochs='reward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf900625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1250a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_df = pd.concat(cohort_epochs['deltaF']['all'])\n",
    "outcome_dfs = []\n",
    "sessions = outcome_df.groupby(outcome_df.index.get_level_values('Unique session'))\n",
    "for sesh in outcome_df.index.get_level_values('Unique session').unique():\n",
    "    shortened_sesh = sesh.split('FOV')[0][:-1]\n",
    "    sesh_df = sessions.get_group(sesh)\n",
    "    check_ID = sesh_df.index.get_level_values(0)[0]\n",
    "    for dysesh in short_term_strategy:\n",
    "        if (check_ID in dysesh) & (shortened_sesh in dysesh) & ('PUPIL' not in dysesh):\n",
    "            outcome_dfs.append(sesh_df)\n",
    "test = pd.concat(outcome_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43887f5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot_calcium(cohort_epochs, channel='Red', epochs=['all'] ,protocols=['N'], outcomes=['hit','FA'], plottype='ROIs', trials='all', event_epochs='reward')\n",
    "# plot_calcium(cohort_epochs, channel='Red', epochs=['all'] ,protocols=['N'], outcomes=['hit','FA'], plottype='ROIs', trials='events', event_epochs='reward')\n",
    "# plot_calcium(cohort_epochs, channel='Red', epochs=['all'] ,protocols=['N'], outcomes=['hit','FA'], plottype='correlated_ROIs', trials='all', event_epochs='reward')\n",
    "plot_pupil(cohort_epochs, epochs=['all'] ,protocols=['Ndis','Nrev'], outcomes=['hit','FA'], plottype='trials', trials='all', event_epochs='reward')\n",
    "plot_pupil(cohort_epochs, epochs=['all'] ,protocols=['Edis','Erev'], outcomes=['hit','FA'], plottype='trials', trials='all', event_epochs='reward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73683e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = outcome_df.groupby([outcome_df.index.get_level_values(0), outcome_df.index.get_level_values('Unique session')]).mean()\n",
    "test[test.index.get_level_values(0) == 'RGECO_GCamP_Batch3_one']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9487dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c252eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calcium(cohort_epochs, channel='Red', epochs=['all'] ,protocols=['E'], outcomes=['hit','FA'], plottype='ROIs', trials='all', event_epochs='reward')\n",
    "plot_calcium(cohort_epochs, channel='Red', epochs=['all'] ,protocols=['E'], outcomes=['hit','FA'], plottype='ROIs', trials='events', event_epochs='reward')\n",
    "plot_calcium(cohort_epochs, channel='Red', epochs=['all'] ,protocols=['E'], outcomes=['hit','FA'], plottype='correlated_ROIs', trials='all', event_epochs='reward')\n",
    "plot_pupil(cohort_epochs, epochs=['all'] ,protocols=['E'], outcomes=['hit','FA'], plottype='trials', trials='all', event_epochs='reward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5736984c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for mouse, mouse_dict in deltaF_pupil.items():\n",
    "    if mouse not in somas:\n",
    "        for ROI, ROI_dict in mouse_dict.items():\n",
    "            deltaF = pd.DataFrame(ROI_dict['deltaF'])\n",
    "            deltaF = (deltaF - deltaF.mean())/deltaF.std(ddof=0)\n",
    "            pupil = pd.DataFrame(ROI_dict['pupil'])\n",
    "            pupil = (pupil - pupil.mean())/pupil.std(ddof=0)\n",
    "            \n",
    "            df = pd.concat([deltaF, pupil], axis=1)\n",
    "            rho = df.corr()\n",
    "            r = rho['deltaF']['pupil']\n",
    "            pval = (df.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape))['deltaF']['pupil']\n",
    "            \n",
    "            if (pval < 0.05) & (abs(r > 0.15)):\n",
    "                fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15,5))\n",
    "                deltaF.plot(ax=ax, color='orange',alpha=0.6)\n",
    "                pupil.plot(ax=ax, color='blue',alpha=0.6)\n",
    "#             break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e5a71f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correlated_ROIs = []\n",
    "for mouse, mouse_dict in cohort_correlations.items():\n",
    "    inter = mouse_dict['inter-compartment']\n",
    "    \n",
    "    for index, rows in inter.iterrows():\n",
    "        ID = mouse+'_'+index\n",
    "        if (rows['avg_r'] > 0.8):\n",
    "            mouse_deltaF = cohort_deltaF[mouse]\n",
    "            sesh = ('_').join(index.split('_')[:-2])\n",
    "            FOV_deltaF = mouse_deltaF[mouse_deltaF.index.get_level_values('Unique session') == sesh]\n",
    "            ROI_deltaF = FOV_deltaF[FOV_deltaF.index.get_level_values('Unique_ROI') == index].iloc[:,2:-1]\n",
    "            if 'Green' in index:\n",
    "                other_pop = FOV_deltaF[FOV_deltaF.index.get_level_values('Channel') == 'Red'].iloc[:,2:-1]\n",
    "                ROI_c = 'green'\n",
    "                other_c = 'red'\n",
    "            else:\n",
    "                other_pop = FOV_deltaF[FOV_deltaF.index.get_level_values('Channel') == 'Green'].iloc[:,2:-1]\n",
    "                ROI_c = 'red'\n",
    "                other_c = 'green'\n",
    "            ROI_flat = ROI_deltaF.to_numpy().flatten()\n",
    "            ROI_flat = (ROI_flat - ROI_flat.min())/(ROI_flat.max()-ROI_flat.min())\n",
    "            other_flat = other_pop.groupby(other_pop.index.get_level_values('Unique_trial')).mean().to_numpy().flatten()\n",
    "            other_flat = (other_flat - other_flat.min())/(other_flat.max()-other_flat.min())\n",
    "            plt.figure(figsize=(15,4))\n",
    "            plt.plot(ROI_flat, color=ROI_c, alpha=0.7)\n",
    "            plt.plot(other_flat, color=other_c, alpha=0.3)\n",
    "            plt.suptitle(mouse+'_'+index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
